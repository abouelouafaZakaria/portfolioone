<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Data Pipeline on GCP</title>
  <style>
    body {
      font-family: 'Poppins', sans-serif;
      margin: 0;
      background-color: #0d1117;
      color: #e6edf3;
      line-height: 1.8;
      padding: 40px;
    }

    h1 {
      color: #58a6ff;
      text-align: center;
      font-size: 2rem;
    }

    .section {
      margin-bottom: 40px;
    }

    .section h2 {
      color: #7ee787;
      border-left: 4px solid #7ee787;
      padding-left: 10px;
    }

    img {
      width: 100%;
      max-width: 700px;
      display: block;
      margin: 20px auto;
      border-radius: 12px;
      box-shadow: 0 0 15px rgba(0,0,0,0.4);
    }

    .btn-back {
      display: inline-block;
      background-color: #238636;
      color: white;
      padding: 10px 18px;
      border-radius: 6px;
      text-decoration: none;
      font-weight: bold;
      transition: background 0.3s;
    }

    .btn-back:hover {
      background-color: #2ea043;
    }

    .tech-list {
      background-color: #161b22;
      padding: 15px;
      border-radius: 10px;
    }
  </style>
</head>
<body>

  <a href="projects.html" class="btn-back">‚¨Ö Back to Projects</a>

  <h1>End-to-End Data Pipeline on GCP</h1>

  <div class="section">
    <h2>üìã Project Overview</h2>
    <p>
      This project demonstrates the creation of an automated data pipeline using Google Cloud tools.
      It collects raw data from APIs, transforms it with <strong>PySpark</strong>, and loads it into
      <strong>BigQuery</strong> for analytics. The workflow orchestration was handled using
      <strong>Apache Airflow</strong>.
    </p>
  </div>

  <div class="section">
    <h2>üèóÔ∏è Architecture</h2>
    <img src="pipeline.jpg" alt="Pipeline Diagram">
    <p>
      The architecture consists of a data ingestion layer (APIs), a transformation stage (PySpark on Dataproc),
      and a storage layer (BigQuery). Airflow triggers and monitors all stages.
    </p>
  </div>

  <div class="section">
    <h2>üß∞ Stack Used</h2>
    <div class="tech-list">
      <ul>
        <li>Apache Airflow for orchestration</li>
        <li>PySpark for transformation</li>
        <li>BigQuery for storage</li>
        <li>Docker for containerization</li>
        <li>Google Cloud Platform for infrastructure</li>
      </ul>
    </div>
  </div>

  <div class="section">
    <h2>üí° Lessons Learned</h2>
    <p>
      Through this project, I learned how to design reliable ETL pipelines, manage DAG dependencies in Airflow,
      and optimize Spark jobs for large-scale data. It improved my understanding of cloud data flow and monitoring.
    </p>
  </div>

  <div class="section" style="text-align:center;">
    <a href="https://github.com/zakaria/pipeline-gcp" target="_blank" class="btn-back">üîó View on GitHub</a>
  </div>

</body>
</html>
